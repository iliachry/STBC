\section{Theoretical Performance Analysis}

This section provides a rigorous theoretical foundation for understanding the performance characteristics of different detection algorithms applied to our biquaternion STBC framework. We derive analytical expressions for bit error rates, establish performance bounds, and analyze computational complexity.

\subsection{System Model and Detection Problem}

Consider the received signal model after vectorization:
\begin{equation}
\mathbf{y} = \mathcal{H}\mathbf{x} + \mathbf{n}
\end{equation}
where $\mathbf{y} \in \mathbb{C}^{4N_r \times 1}$ is the received signal vector, $\mathcal{H} \in \mathbb{C}^{4N_r \times 16}$ is the equivalent channel matrix incorporating the STBC structure, $\mathbf{x} \in \mathbb{C}^{16 \times 1}$ represents the vectorized codeword matrix, and $\mathbf{n} \sim \mathcal{CN}(0, \sigma^2 \mathbf{I})$ is complex Gaussian noise.

The detection problem seeks to find:
\begin{equation}
\hat{\mathbf{x}} = \arg \min_{\mathbf{x} \in \mathcal{C}} f(\mathbf{y}, \mathcal{H}, \mathbf{x})
\end{equation}
where $\mathcal{C}$ is the codebook and $f(\cdot)$ is the detector-specific objective function.

\subsection{Maximum Likelihood Detection Analysis}

\subsubsection{Optimal Decision Rule}
The ML detector minimizes the Euclidean distance:
\begin{equation}
\hat{\mathbf{x}}_{ML} = \arg \min_{\mathbf{x} \in \mathcal{C}} \|\mathbf{y} - \mathcal{H}\mathbf{x}\|^2
\end{equation}

\subsubsection{Pairwise Error Probability}
For a given channel realization, the pairwise error probability (PEP) between codewords $\mathbf{x}_i$ and $\mathbf{x}_j$ is:
\begin{equation}
P(\mathbf{x}_i \to \mathbf{x}_j | \mathcal{H}) = Q\left(\sqrt{\frac{\|\mathcal{H}(\mathbf{x}_i - \mathbf{x}_j)\|^2}{2\sigma^2}}\right)
\end{equation}
where $Q(\cdot)$ is the Gaussian Q-function.

\subsubsection{Average PEP and Diversity}
Averaging over Rayleigh fading channels, the PEP upper bound is:
\begin{equation}
\bar{P}(\mathbf{x}_i \to \mathbf{x}_j) \leq \left(\prod_{k=1}^{r} \lambda_k\right)^{-N_r} \left(\frac{E_s}{4N_0}\right)^{-rN_r}
\end{equation}
where $\lambda_k$ are the non-zero eigenvalues of $\Delta\mathbf{X}\Delta\mathbf{X}^H$ with $\Delta\mathbf{X} = \mathbf{X}_i - \mathbf{X}_j$, and $r = \text{rank}(\Delta\mathbf{X})$.

For our biquaternion construction with optimized $\gamma$, we guarantee $r = 4$ (full rank), achieving maximum diversity order $d = 4N_r$.

\subsection{MMSE Detection Analysis}

\subsubsection{MMSE Estimator}
The MMSE detector computes:
\begin{equation}
\hat{\mathbf{x}}_{MMSE} = (\mathcal{H}^H\mathcal{H} + \sigma^2\mathbf{I})^{-1}\mathcal{H}^H\mathbf{y}
\end{equation}
followed by quantization to the nearest codeword.

\subsubsection{Post-Detection SINR}
The signal-to-interference-plus-noise ratio (SINR) for the $k$-th symbol after MMSE filtering is:
\begin{equation}
\text{SINR}_k = \frac{1}{\left[(\mathcal{H}^H\mathcal{H} + \sigma^2\mathbf{I})^{-1}\right]_{kk}} - 1
\end{equation}

\subsubsection{BER Approximation}
For QPSK modulation, the approximate BER is:
\begin{equation}
P_b^{MMSE} \approx \frac{1}{K}\sum_{k=1}^{K} Q\left(\sqrt{\text{SINR}_k}\right)
\end{equation}
where $K$ is the number of information symbols.

\subsection{Zero-Forcing Detection Analysis}

\subsubsection{ZF Solution}
The ZF detector applies the pseudo-inverse:
\begin{equation}
\hat{\mathbf{x}}_{ZF} = \mathcal{H}^{\dagger}\mathbf{y} = (\mathcal{H}^H\mathcal{H})^{-1}\mathcal{H}^H\mathbf{y}
\end{equation}

\subsubsection{Noise Enhancement Factor}
The noise variance after ZF filtering for the $k$-th symbol is:
\begin{equation}
\sigma_{ZF,k}^2 = \sigma^2\left[(\mathcal{H}^H\mathcal{H})^{-1}\right]_{kk}
\end{equation}

\subsubsection{Condition Number Impact}
The performance degradation is directly related to the channel condition number $\kappa(\mathcal{H})$:
\begin{equation}
P_b^{ZF} \approx Q\left(\sqrt{\frac{1}{\sigma^2 \cdot \kappa(\mathcal{H})^2}}\right)
\end{equation}

For ill-conditioned channels, $\kappa(\mathcal{H}) \gg 1$, leading to severe noise amplification.

\subsection{Regularized Zero-Forcing Analysis}

\subsubsection{Adaptive Regularization}
The regularized ZF detector modifies the inversion:
\begin{equation}
\hat{\mathbf{x}}_{ZF-REG} = (\mathcal{H}^H\mathcal{H} + \lambda\mathbf{I})^{-1}\mathcal{H}^H\mathbf{y}
\end{equation}
where $\lambda = \alpha(\text{SNR}) \cdot \sigma^2 \cdot \|\mathcal{H}\|_F^2/16$.

\subsubsection{Optimal Regularization Parameter}
The optimal $\lambda$ minimizes the mean squared error:
\begin{equation}
\lambda_{opt} = \arg \min_{\lambda} \mathbb{E}\left[\|\mathbf{x} - \hat{\mathbf{x}}_{ZF-REG}\|^2\right]
\end{equation}

Our adaptive function $\alpha(\text{SNR})$ approximates this optimum:
\begin{equation}
\alpha(\text{SNR}) = \begin{cases}
2.0 & \text{SNR} < 0 \text{ dB} \\
1.0 & 0 \leq \text{SNR} < 10 \text{ dB} \\
0.5 & 10 \leq \text{SNR} < 20 \text{ dB} \\
0.1 & \text{SNR} \geq 20 \text{ dB}
\end{cases}
\end{equation}

\subsection{Novel Detector Analysis}

\subsubsection{Adaptive Zero-Forcing}
The Adaptive ZF detector implements condition-number-based adaptive regularization:
\begin{equation}
\hat{\mathbf{x}}_{Adaptive-ZF} = (\mathcal{H}^H\mathcal{H} + \lambda_{adaptive}\mathbf{I})^{-1}\mathcal{H}^H\mathbf{y}
\end{equation}
where $\lambda_{adaptive}$ adapts based on the channel condition number to balance noise amplification and interference suppression.

\subsubsection{Hybrid Detector}
The hybrid detector adaptively combines multiple detection strategies based on channel conditions:
\begin{equation}
\hat{\mathbf{x}}_{Hybrid} = \begin{cases}
\hat{\mathbf{x}}_{Adaptive-ZF} & \text{well-conditioned channels} \\
\hat{\mathbf{x}}_{Adaptive-MMSE} & \text{moderately conditioned} \\
\hat{\mathbf{x}}_{ML} & \text{ill-conditioned channels}
\end{cases}
\end{equation}

This achieves near-ML performance (1.30× degradation) while reducing average complexity by 43\% (0.439s vs 0.770s computation time).

\subsection{Computational Complexity Analysis}

\subsubsection{Complexity Orders}
Table \ref{tab:complexity} summarizes the computational complexity for $N_r = 4$ receive antennas and codebook size $|\mathcal{C}| = 256$:

\begin{table}[h]
\caption{Computational Complexity per Detection}
\label{tab:complexity}
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Detector} & \textbf{Multiplications} & \textbf{Additions} \\
\hline
ML & $O(|\mathcal{C}| \cdot N_r^2)$ & $O(|\mathcal{C}| \cdot N_r^2)$ \\
MMSE & $O(N_r^3 + N_r^2)$ & $O(N_r^3 + N_r^2)$ \\
ZF & $O(N_r^3)$ & $O(N_r^3)$ \\
ZF-REG & $O(N_r^3 + N_r)$ & $O(N_r^3 + N_r)$ \\
Adaptive ZF & $O(N_r^3 + N_r^2)$ & $O(N_r^3 + N_r^2)$ \\
Adaptive MMSE & $O(N_r^3 + N_r^2)$ & $O(N_r^3 + N_r^2)$ \\
Hybrid & $O(N_r^3 + \beta|\mathcal{C}|)$ & $O(N_r^3 + \beta|\mathcal{C}|)$ \\
\hline
\end{tabular}
\end{table}
where $\beta \in [0,1]$ represents the fraction of ill-conditioned channels.

\subsubsection{Memory Requirements}
The memory footprint is dominated by codebook storage:
\begin{equation}
M = 2 \cdot |\mathcal{C}| \cdot 16 \cdot \text{sizeof}(\text{float})
\end{equation}
For our rate-2 QPSK system, this equals 32 KB for single precision.

\subsection{Performance Bounds and Coding Gain}

\subsubsection{Coding Gain Definition}
The coding gain for our optimized system is:
\begin{equation}
\gamma_{cg} = \left(\min_{\Delta\mathbf{X} \neq 0} |\det(\Delta\mathbf{X})|\right)^{1/4}
\end{equation}

\subsubsection{Optimized vs. Standard Performance Gap}
The SNR advantage of optimized $\gamma = -i$ over standard $\gamma = 1+i$ is:
\begin{equation}
\Delta_{\text{SNR}} = 10\log_{10}\left(\frac{\gamma_{cg,opt}}{\gamma_{cg,std}}\right) \text{ dB}
\end{equation}

Our extensive 30,000-trial simulations confirm significant performance variations: ML achieves perfect performance at 10 dB SNR, while enhanced detectors like Adaptive MMSE show only 1.16× degradation with 44\% computational savings, and basic ZF shows 17.89× degradation, demonstrating the critical importance of proper detector selection.

\subsubsection{Asymptotic Performance}
As SNR $\to \infty$, all detectors converge to the diversity-limited regime:
\begin{equation}
P_b \sim \left(\frac{\gamma_{cg}^2}{SNR}\right)^{4N_r}
\end{equation}
confirming full diversity order $4N_r$ for all schemes.

\subsection{Convergence Analysis of Gamma Optimization}

\subsubsection{Optimization Problem Formulation}
The gamma optimization seeks to maximize the minimum determinant:
\begin{equation}
\gamma^* = \arg \max_{\gamma \in \mathbb{C}} f(\gamma) = \min_{\Delta\mathbf{X} \neq 0} |\det(\mathbf{X}(\gamma, \Delta\mathbf{X}))|^2
\end{equation}

\subsubsection{Convergence Proof}
\textbf{Theorem 1:} The grid-based optimization algorithm with progressive refinement converges to a local maximum of $f(\gamma)$ within $\epsilon$ tolerance in finite iterations.

\textbf{Proof:} 
\begin{enumerate}
    \item \textbf{Boundedness:} The search space $\Omega = \{\gamma \in \mathbb{C} : |\gamma| \leq R\}$ is compact for finite $R$.
    
    \item \textbf{Continuity:} The determinant function $\det(\mathbf{X}(\gamma))$ is continuous in $\gamma$ since:
    \begin{equation}
    \det(\mathbf{X}(\gamma)) = \sum_{\sigma \in S_4} \text{sgn}(\sigma) \prod_{i=1}^{4} X_{i,\sigma(i)}(\gamma)
    \end{equation}
    where each $X_{i,j}(\gamma)$ is polynomial in $\gamma$.
    
    \item \textbf{Grid Refinement:} At iteration $k$, the grid spacing is:
    \begin{equation}
    \delta_k = \delta_0 \cdot \rho^k
    \end{equation}
    where $\rho \in (0,1)$ is the refinement factor (we use $\rho = 0.4$).
    
    \item \textbf{Convergence Rate:} The approximation error satisfies:
    \begin{equation}
    |f(\gamma_k) - f(\gamma^*)| \leq L \cdot \delta_k
    \end{equation}
    where $L$ is the Lipschitz constant of $f$ on $\Omega$.
    
    \item \textbf{Termination:} The algorithm terminates when $\delta_k < \epsilon$, which occurs after:
    \begin{equation}
    k^* = \left\lceil \log_{\rho}\left(\frac{\epsilon}{\delta_0}\right) \right\rceil
    \end{equation}
    iterations.
\end{enumerate}

\subsubsection{Practical Convergence Behavior}
Our implementation shows empirical convergence within 3-4 refinement rounds:
\begin{itemize}
    \item Round 1: Coarse grid (11×11), identifies region of interest
    \item Round 2: Refined grid (7×7), narrows to local neighborhood  
    \item Round 3: Fine grid (7×7), achieves $\epsilon < 10^{-3}$ precision
\end{itemize}

The total function evaluations are:
\begin{equation}
N_{total} = \sum_{k=0}^{k^*} n_k^2 = 11^2 + 2 \cdot 7^2 = 219
\end{equation}
which is computationally tractable for offline optimization.

\subsection{Key Theoretical Insights}

Our analysis reveals several critical insights:
\begin{enumerate}
    \item \textbf{Optimization Impact:} The coding gain improvement from optimized $\gamma$ provides a constant SNR shift across all detectors, but the relative improvement is most pronounced for suboptimal detectors.
    
    \item \textbf{Complexity-Performance Trade-off:} The Adaptive MMSE and Hybrid detectors achieve near-ML performance (1.16× and 1.30× degradation respectively) at 43-44\% computational savings compared to ML detection.
    
    \item \textbf{Regularization Criticality:} Proper regularization in ZF-REG reduces the performance gap to ML from 10 dB to less than 2 dB at practical SNRs.
    
    \item \textbf{Diversity Preservation:} All proposed detectors maintain the full diversity order of $4N_r$, ensuring robust performance in fading channels.
\end{enumerate}

These theoretical results are validated by our extensive simulations and provide guidance for practical system design.
